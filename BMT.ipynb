{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4xnkGyiZzm9",
        "outputId": "af318713-f606-46f9-c86b-fd2e32a685ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaC8pFTs999Q"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = '/content/drive/MyDrive/train/outputs/BMT_NND_WM110.tar'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCdeXzBQOo9W"
      },
      "source": [
        "# Инициализация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GeV-eQ7VgZR",
        "outputId": "750a5b1a-93fc-4ad7-bf22-e8769f6144c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221213.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.9 MB/s \n",
            "\u001b[?25hCollecting jsonpickle\n",
            "  Downloading jsonpickle-3.0.0-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore) (1.21.6)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (2.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore) (0.8.10)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath>=0.1.7->fvcore) (4.4.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221213-py3-none-any.whl size=61498 sha256=00fea8cabff6d19d97cdf6ad049297ef4dfc24aa71b28ab88419c77ec9a443d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/6d/5c/4fd3efe9b62aeae1e7e68204b54487df288e58e28f3d13fa1e\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=3919d4e6d79d070b94c780e3ca7e90404390e011b0539300dfc2448bd83cd29d\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: portalocker, yacs, iopath, jsonpickle, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221213 iopath-0.1.10 jsonpickle-3.0.0 portalocker-2.6.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install fvcore jsonpickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIWbU1MGRsNn",
        "outputId": "609c87cb-fd54-4770-9182-b53fcb5e11af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'BMT'...\n",
            "remote: Enumerating objects: 2103, done.\u001b[K\n",
            "remote: Counting objects: 100% (2103/2103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2091/2091), done.\u001b[K\n",
            "remote: Total 2103 (delta 12), reused 2064 (delta 9), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2103/2103), 235.62 MiB | 15.66 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "Checking out files: 100% (2066/2066), done.\n",
            "/content/BMT\n",
            "Already on 'develop'\n",
            "Your branch is up to date with 'origin/develop'.\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b develop --single-branch --depth 1 'https://github.com/maloxit/BMT.git'\n",
        "%cd /content/BMT\n",
        "!git checkout develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkedGrutqd8W",
        "outputId": "4aba4bf0-0f2a-408b-e2b8-bcc660c083af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BMT\n"
          ]
        }
      ],
      "source": [
        "%cd /content/BMT\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.utils.data as torchdt\n",
        "from itertools import chain\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from model.option import get_opts\n",
        "from model.dataset import MakeupDataset\n",
        "from model.loss import SAATDLoss, SAATGLoss\n",
        "from model.model import get_generator, get_dis_non_makeup, get_dis_makeup\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABP8cRq7qjIb"
      },
      "outputs": [],
      "source": [
        "def get_torch_device(opts):\n",
        "    if opts.platform == 'GPU' and torch.cuda.is_available():\n",
        "        return torch.device('cuda:{}'.format(opts.device_id))\n",
        "    else:\n",
        "        return torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEWIYIiMq2QL"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "opts = argparse.Namespace(**{\n",
        "    'warp_dir': '/content/BMT/datasets/train/images/warp_tmp',\n",
        "    'warp_alt_dir': '/content/BMT/datasets/train/images/warp',\n",
        "    'warp_storage_dir': '/content/drive/MyDrive/train/warp',\n",
        "    'subset_config_files': \n",
        "    [\n",
        "        'datasets/train_makeup_blue_shades.json',\n",
        "        'datasets/train_makeup_dark_shades.json',\n",
        "        'datasets/train_makeup_new_makeup.json',\n",
        "        'datasets/train_makeup_other.json',\n",
        "        'datasets/train_makeup_purpule_shades.json',\n",
        "        'datasets/train_makeup_red_eyes.json',\n",
        "        'datasets/train_non_makeup.json'\n",
        "    ],\n",
        "    'input_dim': 3,\n",
        "    'output_dim': 3,\n",
        "    'semantic_dim': 18,\n",
        "    'batch_size': 1,\n",
        "    'resize_size': 286,\n",
        "    'crop_size': 256,\n",
        "    'flip': True,\n",
        "    'nThreads': 0,\n",
        "\n",
        "    # platform related\n",
        "    'platform': 'GPU',\n",
        "    'device_id': 0,\n",
        "    'device_num': 1,\n",
        "\n",
        "    # ouptput related\n",
        "    'name': 'BMT_NND_WM',\n",
        "    'outputs_dir': '/content/drive/MyDrive/train/outputs/',\n",
        "    'print_iter': 1,\n",
        "    'save_imgs': True,\n",
        "    'save_checkpoint_epochs': 5,\n",
        "\n",
        "    # weight\n",
        "    'gan_mode': 'lsgan',\n",
        "    'rec_weight': 1,\n",
        "    'CP_weight': 0.05,\n",
        "    'GP_weight': 0.025,\n",
        "    'cycle_weight': 1,\n",
        "    'adv_weight': 1,\n",
        "    'latent_weight': 0.1,\n",
        "    'semantic_weight': 1,\n",
        "\n",
        "    # training related\n",
        "    'init_type': 'normal',\n",
        "    'init_gain': 0.02,\n",
        "    'beta1': 0.5,\n",
        "    'beta2': 0.999,\n",
        "\n",
        "    'dis_scale': 3,\n",
        "    'dis_norm': 'None',\n",
        "    'dis_spectral_norm': True,\n",
        "    'lr_policy': 'lambda',\n",
        "    'max_epoch': 1000,\n",
        "    'n_epochs': 1000,\n",
        "    'n_epochs_decay': 500,\n",
        "\n",
        "    'resume': None,\n",
        "    'num_residule_block': 4,\n",
        "    'lr': 0.0002\n",
        "})\n",
        "test_opts = argparse.Namespace(**{\n",
        "    'warp_dir': '/content/BMT/datasets/test/images/warp_tmp',\n",
        "    'warp_alt_dir': '/content/BMT/datasets/test/images/warp',\n",
        "    'warp_storage_dir': '/content/drive/MyDrive/test/warp',\n",
        "    'subset_config_files': \n",
        "    [\n",
        "        'datasets/test_makeup.json',\n",
        "        'datasets/test_non_makeup.json'\n",
        "    ],\n",
        "    'input_dim': 3,\n",
        "    'output_dim': 3,\n",
        "    'semantic_dim': 18,\n",
        "    'batch_size': 1,\n",
        "    'resize_size': 286,\n",
        "    'crop_size': 256,\n",
        "    'flip': True,\n",
        "    'nThreads': 0,\n",
        "\n",
        "    # platform related\n",
        "    'platform': 'GPU',\n",
        "    'device_id': 0,\n",
        "    'device_num': 1,\n",
        "\n",
        "    # ouptput related\n",
        "    'name': 'BMT_ND_WM',\n",
        "    'outputs_dir': '/content/drive/MyDrive/test/outputs/',\n",
        "    'print_iter': 1,\n",
        "    'save_imgs': True,\n",
        "    'save_checkpoint_epochs': 5,\n",
        "\n",
        "    # weight\n",
        "    'gan_mode': 'lsgan',\n",
        "    'rec_weight': 1,\n",
        "    'CP_weight': 0.05,\n",
        "    'GP_weight': 0.025,\n",
        "    'cycle_weight': 1,\n",
        "    'adv_weight': 1,\n",
        "    'latent_weight': 0.1,\n",
        "    'semantic_weight': 1,\n",
        "\n",
        "    # training related\n",
        "    'init_type': 'normal',\n",
        "    'init_gain': 0.02,\n",
        "    'beta1': 0.5,\n",
        "    'beta2': 0.999,\n",
        "\n",
        "    'dis_scale': 3,\n",
        "    'dis_norm': 'None',\n",
        "    'dis_spectral_norm': True,\n",
        "    'lr_policy': 'lambda',\n",
        "    'max_epoch': 1000,\n",
        "    'n_epochs': 1000,\n",
        "    'n_epochs_decay': 500,\n",
        "\n",
        "    'resume': None,\n",
        "    'num_residule_block': 4,\n",
        "    'lr': 0.0002\n",
        "})\n",
        "\n",
        "device = get_torch_device(opts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxcKJ4ISq8Nh",
        "outputId": "d657e0be-8afe-486a-83a0-a5db922075a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n"
          ]
        }
      ],
      "source": [
        "# model G and D\n",
        "G = get_generator(opts, device)\n",
        "D_non_makeup = get_dis_non_makeup(opts, device)\n",
        "D_makeup = get_dis_makeup(opts, device)\n",
        "\n",
        "# loss G and D\n",
        "loss_G = SAATGLoss(opts, G, D_non_makeup, D_makeup)\n",
        "loss_D = SAATDLoss(opts, D_non_makeup, D_makeup)\n",
        "\n",
        "# optimizer G and D\n",
        "optimizer_G = torch.optim.Adam(G.parameters(), opts.lr, betas=(opts.beta1, opts.beta2), weight_decay=0.0001)\n",
        "optimizer_D = torch.optim.Adam(chain(D_non_makeup.parameters(), D_makeup.parameters()), opts.lr,\n",
        "                                betas=(opts.beta1, opts.beta2), weight_decay=0.0001)\n",
        "\n",
        "last_epoch = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkUUYprKaZeZ"
      },
      "outputs": [],
      "source": [
        "# Load checkpoint\n",
        "\n",
        "def load_checkpoint(checkpoint_path, G=None, D_non_makeup=None, D_makeup=None, optimizer_G=None, optimizer_D=None):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    if G is not None:\n",
        "        G.load_state_dict(checkpoint['model_G_state_dict'])\n",
        "    if D_non_makeup is not None:\n",
        "        D_non_makeup.load_state_dict(checkpoint['model_D_non_makeup_state_dict'])\n",
        "    if D_makeup is not None:\n",
        "        D_makeup.load_state_dict(checkpoint['model_D_makeup_state_dict'])\n",
        "    if optimizer_G is not None:\n",
        "        optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
        "    if optimizer_D is not None:\n",
        "        optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])\n",
        "    last_epoch = checkpoint['epoch']\n",
        "    last_g_loss = checkpoint['g_loss']\n",
        "    last_d_loss = checkpoint['d_loss']\n",
        "\n",
        "    print(\"Loading checkpoint\")\n",
        "    print(\"epoch:\\t\", last_epoch)\n",
        "    print(\"g_loss\\t\", last_g_loss)\n",
        "    print(\"d_loss\\t\", last_d_loss)\n",
        "    print(\"\\n\")\n",
        "    return last_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5uEP4BdQWsY"
      },
      "source": [
        "# Загрузка сгенерированной части датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvvDrAVYceIo",
        "outputId": "72f43d98-7e70-477d-b547-cb8e73713af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/train\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/train\n",
        "!tar -xPf new_warp1.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp2.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp3.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp4.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp5.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp6.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp7.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp8.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp9.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp10.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp11.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp12.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp13.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp14.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp15.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp16.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp17.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp18.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp19.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp20.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp21.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp22.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp23.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp24.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp25.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp26.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp27.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp28.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp29.tar -C /content/BMT/datasets/train/images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biDEiXuLPSZ5"
      },
      "source": [
        "# Тест"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDkpxD4-f_gv",
        "outputId": "638a737e-8762-4e3a-a3c0-7c9b55955b82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BMT\n",
            "non_makeup size: 2 makeup size: 12\n",
            "Loading checkpoint\n",
            "epoch:\t 110\n",
            "g_loss\t -2.249089557329813\n",
            "d_loss\t 0.4295520579814914\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [01:24<00:00,  3.51s/it]\n"
          ]
        }
      ],
      "source": [
        "def write_test_pair_img(result_dir, test_pair_img, iter):\n",
        "    if not os.path.exists(result_dir):\n",
        "        os.makedirs(result_dir)\n",
        "    img_filename = '%s/gen_%05d.png' % (result_dir, iter)\n",
        "    torchvision.utils.save_image(test_pair_img / 2 + 0.5, img_filename, nrow=1)\n",
        "\n",
        "\n",
        "def normalize_image(x):\n",
        "    return x[:, 0:3, :, :]\n",
        "\n",
        "\n",
        "def get_img(non_makeup, makeup, z_transfer, z_removal, transfer_g, removal_g, z_rec_non_makeup, z_rec_makeup, z_cycle_non_makeup, z_cycle_makeup):\n",
        "    #non_makeup_down = normalize_image(F.interpolate(non_makeup, scale_factor=0.25, mode='nearest'))\n",
        "    #n, c, h, w = non_makeup_down.shape\n",
        "    #non_makeup_down_warp = torch.bmm(non_makeup_down.view(n, c, h * w), mapY)  # n*HW*1\n",
        "    #non_makeup_down_warp = non_makeup_down_warp.view(n, c, h, w)\n",
        "    #non_makeup_warp = F.interpolate(non_makeup_down_warp, scale_factor=4)\n",
        "\n",
        "    #makeup_down = normalize_image(F.interpolate(makeup, scale_factor=0.25, mode='nearest'))\n",
        "    #n, c, h, w = makeup_down.shape\n",
        "    #makeup_down_warp = torch.bmm(makeup_down.view(n, c, h * w), mapX)  # n*HW*1\n",
        "    #makeup_down_warp = makeup_down_warp.view(n, c, h, w)\n",
        "    #makeup_warp = F.interpolate(makeup_down_warp, scale_factor=4)\n",
        "\n",
        "    n, c, h, w = non_makeup.shape\n",
        "\n",
        "    canvas = torch.ones([1, c, int(h * 4.5), int(w * 4)])\n",
        "\n",
        "\n",
        "    images_non_makeup = normalize_image(non_makeup).detach()\n",
        "    images_makeup = normalize_image(makeup).detach()\n",
        "    images_z_transfer = normalize_image(z_transfer).detach()\n",
        "    images_z_removal = normalize_image(z_removal).detach()\n",
        "    images_g_transfer = normalize_image(transfer_g).detach()\n",
        "    images_g_removal = normalize_image(removal_g).detach()\n",
        "    images_z_rec_non_makeup = normalize_image(z_rec_non_makeup).detach()\n",
        "    images_z_rec_makeup = normalize_image(z_rec_makeup).detach()\n",
        "    images_z_cycle_non_makeup = normalize_image(z_cycle_non_makeup).detach()\n",
        "    images_z_cycle_makeup = normalize_image(z_cycle_makeup).detach()\n",
        "\n",
        "    canvas[0:1, :, int(h * 1): int(h * 1) + h, int(w * 0):int(w * 0)+w] = images_non_makeup[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 2.5): int(h * 2.5) + h, int(w * 0):int(w * 0)+w] = images_makeup[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 1): int(h * 1) + h, int(w * 1):int(w * 1)+w] = images_z_transfer[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 2.5): int(h * 2.5) + h, int(w * 1):int(w * 1)+w] = images_z_removal[0:1, ::]\n",
        "\n",
        "    canvas[0:1, :, int(h * 1): int(h * 1) + h, int(w * 2):int(w * 2)+w] = images_z_cycle_non_makeup[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 2.5): int(h * 2.5) + h, int(w * 2):int(w * 2)+w] = images_z_cycle_makeup[0:1, ::]\n",
        "\n",
        "    canvas[0:1, :, int(h * 1): int(h * 1) + h, int(w * 3):int(w * 3)+w] = images_z_rec_non_makeup[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 2.5): int(h * 2.5) + h, int(w * 3):int(w * 3)+w] = images_z_rec_makeup[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 0): int(h * 0) + h, int(w * 1):int(w * 1)+w] = images_g_transfer[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 3.5): int(h * 3.5) + h, int(w * 1):int(w * 1)+w] = images_g_removal[0:1, ::]\n",
        "\n",
        "\n",
        "\n",
        "    #row1 = torch.cat((images_non_makeup[0:1, ::],images_makeup[0:1, ::], makeup_warp[0:1, ::], images_z_transfer[0:1, ::], images_z_removal[0:1, ::], images_g_transfer[0:1, ::], images_g_removal[0:1, ::]), 3)\n",
        "    return canvas\n",
        "\n",
        "\n",
        "%cd /content/BMT\n",
        "checkpoint_path2 = '/content/drive/MyDrive/train/outputs/BMT_ND_WM240.tar'\n",
        "\n",
        "#dataset = MakeupDataset(opts, device, ['datasets/train_non_makeup.json', 'datasets/train_makeup_new_makeup.json'], transform=False, need_pgt=True, all_comb=False)\n",
        "dataset = MakeupDataset(test_opts, device, ['datasets/test_non_makeup.json', 'datasets/test_makeup.json'], transform=False, need_pgt=True, all_comb=True)\n",
        "data_loader = torchdt.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=opts.nThreads)\n",
        "\n",
        "last_epoch = load_checkpoint(checkpoint_path, G)\n",
        "#last_epoch = load_checkpoint(checkpoint_path2, G)\n",
        "G.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(tqdm(data_loader)):\n",
        "        non_makeup = data['non_makeup'].to(device)\n",
        "        makeup = data['makeup'].to(device)\n",
        "        transfer_g = data['transfer'].to(device)\n",
        "        removal_g = data['removal'].to(device)\n",
        "        non_makeup_parse = data['non_makeup_parse'].to(device)\n",
        "        makeup_parse = data['makeup_parse'].to(device)\n",
        "\n",
        "        z_transfer, z_removal, z_rec_non_makeup, z_rec_makeup, z_cycle_non_makeup, z_cycle_makeup, _, _ =\\\n",
        "            G(non_makeup, makeup, non_makeup_parse, makeup_parse)\n",
        "        #img = get_img(non_makeup, makeup, mapX, mapY, z_transfer, z_removal, transfer_g, removal_g)\n",
        "        img = get_img(non_makeup, makeup, z_transfer, z_removal, transfer_g, removal_g, z_rec_non_makeup, z_rec_makeup, z_cycle_non_makeup, z_cycle_makeup)\n",
        "        write_test_pair_img(test_opts.outputs_dir + 'res{}'.format(last_epoch), img, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmo8nbR1tFGn",
        "outputId": "a2e26d58-726b-4d9a-ce1a-660ea5008f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BMT\n",
            "non_makeup size: 2 makeup size: 12\n",
            "initialize network with normal\n",
            "Loading checkpoint\n",
            "epoch:\t 40\n",
            "g_loss\t -2.0819977156321214\n",
            "d_loss\t 0.4374274258812266\n",
            "\n",
            "\n",
            "Loading checkpoint\n",
            "epoch:\t 240\n",
            "g_loss\t -2.3929487947622934\n",
            "d_loss\t 0.43149305939674387\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:09<00:00,  2.59it/s]\n"
          ]
        }
      ],
      "source": [
        "%cd /content/BMT\n",
        "\n",
        "checkpoint_path1 = '/content/drive/MyDrive/train/outputs/BMT_NND_WM40.tar'\n",
        "checkpoint_path2 = '/content/drive/MyDrive/train/outputs/BMT_ND_WM240.tar'\n",
        "#checkpoint_path2 = '/content/drive/MyDrive/train/outputs/BMT_NND_WM85.tar'\n",
        "\n",
        "dataset = MakeupDataset(test_opts, device, test_opts.subset_config_files, transform=False, need_pgt=True, all_comb=True)\n",
        "data_loader = torchdt.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=opts.nThreads)\n",
        "\n",
        "G_old = get_generator(opts, device)\n",
        "last_epoch1 = load_checkpoint(checkpoint_path1, G)\n",
        "last_epoch2 = load_checkpoint(checkpoint_path2, G_old)\n",
        "G.eval()\n",
        "G_old.eval()\n",
        "refs = []\n",
        "trans1 = []\n",
        "trans2 = []\n",
        "pgts = []\n",
        "bases = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(tqdm(data_loader)):\n",
        "        non_makeup = data['non_makeup'].to(device)\n",
        "        makeup = data['makeup'].to(device)\n",
        "        transfer_g = data['transfer'].to(device)\n",
        "        removal_g = data['removal'].to(device)\n",
        "        non_makeup_parse = data['non_makeup_parse'].to(device)\n",
        "        makeup_parse = data['makeup_parse'].to(device)\n",
        "\n",
        "        base_index = i // dataset.makeup_size\n",
        "        ref_index = i % dataset.makeup_size\n",
        "        if ref_index == 0:\n",
        "            bases.append(non_makeup[0].detach().cpu() / 2 + 0.5)\n",
        "            refs.append([])\n",
        "            trans1.append([])\n",
        "            trans2.append([])\n",
        "            pgts.append([])\n",
        "        refs[base_index].append(makeup[0].detach().cpu() / 2 + 0.5)\n",
        "        pgts[base_index].append(transfer_g[0].detach().cpu() / 2 + 0.5)\n",
        "        z_transfer1, z_removal1 =\\\n",
        "            G.get_transfers(non_makeup, makeup, non_makeup_parse, makeup_parse)\n",
        "        z_transfer2, z_removal2 =\\\n",
        "            G_old.get_transfers(non_makeup, makeup, non_makeup_parse, makeup_parse)\n",
        "        trans1[base_index].append(z_transfer1[0].detach().cpu() / 2 + 0.5)\n",
        "        trans2[base_index].append(z_transfer2[0].detach().cpu() / 2 + 0.5)\n",
        "    nrow = 6\n",
        "    plain = torch.ones_like(bases[0])\n",
        "    for i in range(dataset.non_makeup_size):\n",
        "        for j in range((dataset.makeup_size + nrow - 1) // nrow):\n",
        "            imgs = []\n",
        "            imgs.append(bases[i])\n",
        "            imgs += refs[i][j*nrow:min((j+1)*nrow, dataset.makeup_size)]\n",
        "            imgs.append(plain)\n",
        "            imgs += trans2[i][j*nrow:min((j+1)*nrow, dataset.makeup_size)]\n",
        "            imgs.append(plain)\n",
        "            imgs += trans2[i][j*nrow:min((j+1)*nrow, dataset.makeup_size)]\n",
        "            imgs.append(plain)\n",
        "            imgs += trans1[i][j*nrow:min((j+1)*nrow, dataset.makeup_size)]\n",
        "            imgs.append(plain)\n",
        "            imgs += pgts[i][j*nrow:min((j+1)*nrow, dataset.makeup_size)]\n",
        "            result_dir = test_opts.outputs_dir + 'res{}_{}'.format(last_epoch1, last_epoch2)\n",
        "            if not os.path.exists(result_dir):\n",
        "                os.makedirs(result_dir)\n",
        "            img_filename = '%s/table_%05d.png' % (result_dir, i * 10 + j)\n",
        "            torchvision.utils.save_image(imgs, img_filename, nrow=1 + min(nrow, dataset.makeup_size - j*nrow))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkuxG4c1PYgD"
      },
      "source": [
        "# Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JASQP1MjqYbH",
        "outputId": "c7307d3e-83e7-438e-ee07-1e4a0445f895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BMT\n",
            "non_makeup size: 300 makeup size: 183\n",
            "Loading checkpoint\n",
            "epoch:\t 90\n",
            "g_loss\t -1.9061052970091505\n",
            "d_loss\t 0.4246068192521732\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:26<00:00,  1.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 91\n",
            "g_loss    :\t -2.1571429006258653 \tdiff:\t -2.1571429006258653\n",
            "d_loss    :\t 0.4305417282382648 \tdiff:\t 0.4305417282382648\n",
            "G_GAN     :\t 0.3479786315903652 \tdiff:\t 0.3479786315903652\n",
            "G_rec     :\t 0.06303675756703042 \tdiff:\t 0.06303675756703042\n",
            "G_cycle   :\t 0.11193204536935783 \tdiff:\t 0.11193204536935783\n",
            "G_semantic:\t 0.054135576064745304 \tdiff:\t 0.054135576064745304\n",
            "G_SPL     :\t -2.734225913408744 \tdiff:\t -2.734225913408744\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:09<00:00,  1.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 92\n",
            "g_loss    :\t -2.2037340529759724 \tdiff:\t -0.046591152350107023\n",
            "d_loss    :\t 0.423829158246517 \tdiff:\t -0.0067125699917477966\n",
            "G_GAN     :\t 0.3524521783667941 \tdiff:\t 0.004473546776428916\n",
            "G_rec     :\t 0.06087837721919865 \tdiff:\t -0.0021583803478317717\n",
            "G_cycle   :\t 0.10710371999720725 \tdiff:\t -0.0048283253721505826\n",
            "G_semantic:\t 0.05210870844696969 \tdiff:\t -0.002026867617775617\n",
            "G_SPL     :\t -2.776277040193135 \tdiff:\t -0.042051126784390824\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:04<00:00,  1.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 93\n",
            "g_loss    :\t -2.182346339623134 \tdiff:\t 0.0213877133528384\n",
            "d_loss    :\t 0.43182645618915566 \tdiff:\t 0.007997297942638648\n",
            "G_GAN     :\t 0.34598153983636387 \tdiff:\t -0.006470638530430228\n",
            "G_rec     :\t 0.06086887356170405 \tdiff:\t -9.503657494601414e-06\n",
            "G_cycle   :\t 0.10732405763497246 \tdiff:\t 0.00022033763776521664\n",
            "G_semantic:\t 0.05114237820645129 \tdiff:\t -0.0009663302405183982\n",
            "G_SPL     :\t -2.747663185533286 \tdiff:\t 0.028613854659849114\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:24<00:00,  1.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 94\n",
            "g_loss    :\t -2.1966094326972967 \tdiff:\t -0.014263093074162736\n",
            "d_loss    :\t 0.4284860697388649 \tdiff:\t -0.0033403864502907776\n",
            "G_GAN     :\t 0.34915930723864463 \tdiff:\t 0.0031777674022807623\n",
            "G_rec     :\t 0.06102732221238071 \tdiff:\t 0.00015844865067666386\n",
            "G_cycle   :\t 0.10800096736942408 \tdiff:\t 0.000676909734451614\n",
            "G_semantic:\t 0.05094238256497443 \tdiff:\t -0.00019999564147685917\n",
            "G_SPL     :\t -2.7657394075944124 \tdiff:\t -0.01807622206112658\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [08:59<00:00,  1.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 95\n",
            "g_loss    :\t -2.214950530926386 \tdiff:\t -0.018341098229089248\n",
            "d_loss    :\t 0.4314179601271949 \tdiff:\t 0.0029318903883300274\n",
            "G_GAN     :\t 0.3449928870015961 \tdiff:\t -0.0041664202370485515\n",
            "G_rec     :\t 0.06082865666278726 \tdiff:\t -0.00019866554959345473\n",
            "G_cycle   :\t 0.10779200475683634 \tdiff:\t -0.00020896261258773752\n",
            "G_semantic:\t 0.049832337964075844 \tdiff:\t -0.0011100446008985854\n",
            "G_SPL     :\t -2.7783964159005228 \tdiff:\t -0.012657008306110384\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:17<00:00,  1.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 96\n",
            "g_loss    :\t -2.202809087435405 \tdiff:\t 0.012141443490981008\n",
            "d_loss    :\t 0.4321481843789418 \tdiff:\t 0.0007302242517469026\n",
            "G_GAN     :\t 0.3462185932868736 \tdiff:\t 0.001225706285277517\n",
            "G_rec     :\t 0.059867407535809145 \tdiff:\t -0.0009612491269781129\n",
            "G_cycle   :\t 0.10825750616398125 \tdiff:\t 0.0004655014071449082\n",
            "G_semantic:\t 0.0504869761034368 \tdiff:\t 0.0006546381393609524\n",
            "G_SPL     :\t -2.767639574583889 \tdiff:\t 0.010756841316633903\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:06<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 97\n",
            "g_loss    :\t -2.2119686365127587 \tdiff:\t -0.009159549077353724\n",
            "d_loss    :\t 0.430342320005099 \tdiff:\t -0.001805864373842836\n",
            "G_GAN     :\t 0.343810517990413 \tdiff:\t -0.002408075296460588\n",
            "G_rec     :\t 0.059907272025417985 \tdiff:\t 3.986448960884015e-05\n",
            "G_cycle   :\t 0.10358247442177905 \tdiff:\t -0.004675031742202199\n",
            "G_semantic:\t 0.050183413982624415 \tdiff:\t -0.0003035621208123812\n",
            "G_SPL     :\t -2.769452301259034 \tdiff:\t -0.0018127266751450932\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:02<00:00,  1.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 98\n",
            "g_loss    :\t -2.1809905596574137 \tdiff:\t 0.030978076855344927\n",
            "d_loss    :\t 0.43059390793244035 \tdiff:\t 0.0002515879273413679\n",
            "G_GAN     :\t 0.3474892863712443 \tdiff:\t 0.00367876838083131\n",
            "G_rec     :\t 0.06187002365160788 \tdiff:\t 0.0019627516261898972\n",
            "G_cycle   :\t 0.11100561040800831 \tdiff:\t 0.007423135986229262\n",
            "G_semantic:\t 0.04996045634736305 \tdiff:\t -0.00022295763526136714\n",
            "G_SPL     :\t -2.7513159387089328 \tdiff:\t 0.018136362550101204\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [08:45<00:00,  1.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 99\n",
            "g_loss    :\t -2.2112193667888653 \tdiff:\t -0.030228807131451596\n",
            "d_loss    :\t 0.4281287433703741 \tdiff:\t -0.0024651645620662466\n",
            "G_GAN     :\t 0.3490948132671324 \tdiff:\t 0.0016055268958880542\n",
            "G_rec     :\t 0.060366830457374565 \tdiff:\t -0.0015031931942333168\n",
            "G_cycle   :\t 0.10604429323176574 \tdiff:\t -0.004961317176242569\n",
            "G_semantic:\t 0.04969084337921059 \tdiff:\t -0.00026961296815245644\n",
            "G_SPL     :\t -2.776416137333516 \tdiff:\t -0.025100198624583125\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:10<00:00,  1.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 100\n",
            "g_loss    :\t -2.204085551102957 \tdiff:\t 0.007133815685908207\n",
            "d_loss    :\t 0.4283659253517788 \tdiff:\t 0.00023718198140471047\n",
            "G_GAN     :\t 0.3475809616546502 \tdiff:\t -0.0015138516124821866\n",
            "G_rec     :\t 0.05832402256565474 \tdiff:\t -0.0020428078917198236\n",
            "G_cycle   :\t 0.10720834962929413 \tdiff:\t 0.0011640563975283819\n",
            "G_semantic:\t 0.04872360007717389 \tdiff:\t -0.0009672433020367008\n",
            "G_SPL     :\t -2.7659224831757174 \tdiff:\t 0.01049365415779846\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:09<00:00,  1.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 101\n",
            "g_loss    :\t -2.230457652012508 \tdiff:\t -0.026372100909550777\n",
            "d_loss    :\t 0.43002343018849704 \tdiff:\t 0.0016575048367182266\n",
            "G_GAN     :\t 0.34741988345046865 \tdiff:\t -0.00016107820418154173\n",
            "G_rec     :\t 0.0588742896066097 \tdiff:\t 0.0005502670409549618\n",
            "G_cycle   :\t 0.10602870064750339 \tdiff:\t -0.0011796489817907374\n",
            "G_semantic:\t 0.05000188319338689 \tdiff:\t 0.0012782831162129957\n",
            "G_SPL     :\t -2.792782403348223 \tdiff:\t -0.026859920172505714\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:07<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 102\n",
            "g_loss    :\t -2.1949162248770393 \tdiff:\t 0.035541427135468595\n",
            "d_loss    :\t 0.42480428675810505 \tdiff:\t -0.0052191434303919815\n",
            "G_GAN     :\t 0.3538689831269954 \tdiff:\t 0.006449099676526737\n",
            "G_rec     :\t 0.05983658260081205 \tdiff:\t 0.0009622929942023489\n",
            "G_cycle   :\t 0.10818031001488905 \tdiff:\t 0.0021516093673856623\n",
            "G_semantic:\t 0.048975962621990055 \tdiff:\t -0.0010259205713968322\n",
            "G_SPL     :\t -2.7657780651140524 \tdiff:\t 0.0270043382341707\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:19<00:00,  1.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 103\n",
            "g_loss    :\t -2.207261677980424 \tdiff:\t -0.012345453103384862\n",
            "d_loss    :\t 0.4303071209788322 \tdiff:\t 0.005502834220727171\n",
            "G_GAN     :\t 0.3496532205114094 \tdiff:\t -0.004215762615585983\n",
            "G_rec     :\t 0.05888238148585975 \tdiff:\t -0.0009542011149522994\n",
            "G_cycle   :\t 0.11122870002689467 \tdiff:\t 0.0030483900120056168\n",
            "G_semantic:\t 0.05012144395722626 \tdiff:\t 0.0011454813352362037\n",
            "G_SPL     :\t -2.7771474266681277 \tdiff:\t -0.011369361554075308\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [08:46<00:00,  1.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 104\n",
            "g_loss    :\t -2.2145563288529724 \tdiff:\t -0.007294650872548214\n",
            "d_loss    :\t 0.4305950661500296 \tdiff:\t 0.00028794517119740126\n",
            "G_GAN     :\t 0.34701896894490325 \tdiff:\t -0.0026342515665061517\n",
            "G_rec     :\t 0.05972505379819998 \tdiff:\t 0.0008426723123402258\n",
            "G_cycle   :\t 0.10776008133829253 \tdiff:\t -0.0034686186886021403\n",
            "G_semantic:\t 0.04933237110272313 \tdiff:\t -0.0007890728545031298\n",
            "G_SPL     :\t -2.7783928008056287 \tdiff:\t -0.0012453741375009209\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:04<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 105\n",
            "g_loss    :\t -2.207912160158157 \tdiff:\t 0.006644168694815544\n",
            "d_loss    :\t 0.4254429197311405 \tdiff:\t -0.005152146418889114\n",
            "G_GAN     :\t 0.3517747572489565 \tdiff:\t 0.004755788304053266\n",
            "G_rec     :\t 0.05723818926647493 \tdiff:\t -0.0024868645317250512\n",
            "G_cycle   :\t 0.10396422810299949 \tdiff:\t -0.003795853235293037\n",
            "G_semantic:\t 0.04940672772448104 \tdiff:\t 7.435662175791363e-05\n",
            "G_SPL     :\t -2.7702960606534455 \tdiff:\t 0.008096740152183202\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:05<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 106\n",
            "g_loss    :\t -2.2306589436531072 \tdiff:\t -0.022746783494950407\n",
            "d_loss    :\t 0.42990150541067096 \tdiff:\t 0.004458585679530447\n",
            "G_GAN     :\t 0.3483348124251581 \tdiff:\t -0.003439944823798391\n",
            "G_rec     :\t 0.05697038244177918 \tdiff:\t -0.00026780682469574463\n",
            "G_cycle   :\t 0.10387034627760103 \tdiff:\t -9.38818253984619e-05\n",
            "G_semantic:\t 0.04894142675759076 \tdiff:\t -0.00046530096689028494\n",
            "G_SPL     :\t -2.7887759123037457 \tdiff:\t -0.018479851650300194\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:08<00:00,  1.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 107\n",
            "g_loss    :\t -2.221834903955459 \tdiff:\t 0.008824039697648445\n",
            "d_loss    :\t 0.4317255206406118 \tdiff:\t 0.0018240152299408563\n",
            "G_GAN     :\t 0.34537278580938613 \tdiff:\t -0.0029620266157719954\n",
            "G_rec     :\t 0.06077529167011221 \tdiff:\t 0.0038049092283330282\n",
            "G_cycle   :\t 0.10811435274022026 \tdiff:\t 0.004244006462619229\n",
            "G_semantic:\t 0.04932617140761892 \tdiff:\t 0.0003847446500281626\n",
            "G_SPL     :\t -2.7854235091082047 \tdiff:\t 0.003352403195540976\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [08:51<00:00,  1.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 108\n",
            "g_loss    :\t -2.1921582277615865 \tdiff:\t 0.029676676193872265\n",
            "d_loss    :\t 0.42868071764707566 \tdiff:\t -0.0030448029935361554\n",
            "G_GAN     :\t 0.3494135057590368 \tdiff:\t 0.004040719949650662\n",
            "G_rec     :\t 0.05923361949756102 \tdiff:\t -0.0015416721725511895\n",
            "G_cycle   :\t 0.10933098445390768 \tdiff:\t 0.0012166317136874244\n",
            "G_semantic:\t 0.05154744076420925 \tdiff:\t 0.0022212693565903316\n",
            "G_SPL     :\t -2.7616837825045946 \tdiff:\t 0.023739726603610123\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [08:43<00:00,  1.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 109\n",
            "g_loss    :\t -2.2051544547080986 \tdiff:\t -0.012996226946512035\n",
            "d_loss    :\t 0.4290370864669483 \tdiff:\t 0.00035636881987266555\n",
            "G_GAN     :\t 0.34843697232885706 \tdiff:\t -0.0009765334301797268\n",
            "G_rec     :\t 0.059841972708431994 \tdiff:\t 0.0006083532108709724\n",
            "G_cycle   :\t 0.10611858658008635 \tdiff:\t -0.0032123978738213266\n",
            "G_semantic:\t 0.05018893205357041 \tdiff:\t -0.0013585087106388408\n",
            "G_SPL     :\t -2.76974091847055 \tdiff:\t -0.008057135965955364\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [08:48<00:00,  1.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 110\n",
            "g_loss    :\t -2.249089557329813 \tdiff:\t -0.04393510262171452\n",
            "d_loss    :\t 0.4295520579814914 \tdiff:\t 0.00051497151454305\n",
            "G_GAN     :\t 0.34813859390228097 \tdiff:\t -0.0002983784265760958\n",
            "G_rec     :\t 0.057377185006031034 \tdiff:\t -0.00246478770240096\n",
            "G_cycle   :\t 0.10328553507864269 \tdiff:\t -0.0028330515014436675\n",
            "G_semantic:\t 0.049359832975238424 \tdiff:\t -0.0008290990783319865\n",
            "G_SPL     :\t -2.807250708828481 \tdiff:\t -0.037509790357931116\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [08:49<00:00,  1.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 111\n",
            "g_loss    :\t -2.2368463798363982 \tdiff:\t 0.012243177493414859\n",
            "d_loss    :\t 0.4301769548654557 \tdiff:\t 0.0006248968839643321\n",
            "G_GAN     :\t 0.3472302705180193 \tdiff:\t -0.0009083233842616667\n",
            "G_rec     :\t 0.05637694126914703 \tdiff:\t -0.001000243736884003\n",
            "G_cycle   :\t 0.10311407780835459 \tdiff:\t -0.00017145727028809732\n",
            "G_semantic:\t 0.048040372053659845 \tdiff:\t -0.0013194609215785788\n",
            "G_SPL     :\t -2.7916080438623956 \tdiff:\t 0.015642664966085462\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [08:41<00:00,  1.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch     :\t 112\n",
            "g_loss    :\t -2.245224546194076 \tdiff:\t -0.008378166357677852\n",
            "d_loss    :\t 0.4332207974791529 \tdiff:\t 0.0030438426136971675\n",
            "G_GAN     :\t 0.3461202899849108 \tdiff:\t -0.0011099805331085122\n",
            "G_rec     :\t 0.05746541940568265 \tdiff:\t 0.00108847813653562\n",
            "G_cycle   :\t 0.10347357738633904 \tdiff:\t 0.0003594995779844512\n",
            "G_semantic:\t 0.04829652793826003 \tdiff:\t 0.00025615588460018573\n",
            "G_SPL     :\t -2.8005803586360813 \tdiff:\t -0.008972314773685763\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 275/300 [08:00<00:43,  1.73s/it]"
          ]
        }
      ],
      "source": [
        "%cd /content/BMT\n",
        "\n",
        "dataset = MakeupDataset(opts, device, opts.subset_config_files, transform=True, need_pgt=True, all_comb=False)\n",
        "data_loader = torchdt.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=opts.nThreads)\n",
        "\n",
        "accumulation_steps = 1\n",
        "\n",
        "last_epoch = load_checkpoint(checkpoint_path, G, D_non_makeup, D_makeup, optimizer_G, optimizer_D)\n",
        "#last_epoch = load_checkpoint(checkpoint_path, G, D_non_makeup, D_makeup)\n",
        "G.train()\n",
        "D_non_makeup.train()\n",
        "D_makeup.train()\n",
        "optimizer_G.zero_grad()\n",
        "optimizer_D.zero_grad()\n",
        "\n",
        "\n",
        "class LossStatState:\n",
        "    def __init__(self):\n",
        "        self.d_loss_mean = 0.0\n",
        "        self.g_loss_mean = 0.0\n",
        "        self.loss_G_GAN_mean = 0.0\n",
        "        self.loss_G_rec_mean = 0.0\n",
        "        self.loss_G_cycle_mean = 0.0\n",
        "        self.loss_G_semantic_mean = 0.0\n",
        "        self.loss_G_SPL_mean = 0.0\n",
        "\n",
        "    def print_diff(self, prev_state):\n",
        "        print(\"g_loss    :\\t\", self.g_loss_mean, \"\\tdiff:\\t\", self.g_loss_mean - prev_state.g_loss_mean)\n",
        "        print(\"d_loss    :\\t\", self.d_loss_mean, \"\\tdiff:\\t\", self.d_loss_mean - prev_state.d_loss_mean)\n",
        "        print(\"G_GAN     :\\t\", self.loss_G_GAN_mean, \"\\tdiff:\\t\", self.loss_G_GAN_mean - prev_state.loss_G_GAN_mean)\n",
        "        print(\"G_rec     :\\t\", self.loss_G_rec_mean, \"\\tdiff:\\t\", self.loss_G_rec_mean - prev_state.loss_G_rec_mean)\n",
        "        print(\"G_cycle   :\\t\", self.loss_G_cycle_mean, \"\\tdiff:\\t\", self.loss_G_cycle_mean - prev_state.loss_G_cycle_mean)\n",
        "        print(\"G_semantic:\\t\", self.loss_G_semantic_mean, \"\\tdiff:\\t\", self.loss_G_semantic_mean - prev_state.loss_G_semantic_mean)\n",
        "        print(\"G_SPL     :\\t\", self.loss_G_SPL_mean, \"\\tdiff:\\t\", self.loss_G_SPL_mean - prev_state.loss_G_SPL_mean)\n",
        "\n",
        "\n",
        "loss_stat = LossStatState()\n",
        "for epoch in range(last_epoch + 1, opts.max_epoch):\n",
        "    loss_stat_prev = loss_stat\n",
        "    loss_stat = LossStatState()\n",
        "    \n",
        "    for i, data in enumerate(tqdm(data_loader)):\n",
        "        non_makeup = data['non_makeup'].to(device)\n",
        "        makeup = data['makeup'].to(device)\n",
        "        transfer_g = data['transfer'].to(device)\n",
        "        removal_g = data['removal'].to(device)\n",
        "        non_makeup_parse = data['non_makeup_parse'].to(device)\n",
        "        makeup_parse = data['makeup_parse'].to(device)\n",
        "\n",
        "        g_output = G(non_makeup, makeup, non_makeup_parse, makeup_parse)\n",
        "\n",
        "        z_transfer = g_output[0]\n",
        "        z_removal = g_output[1]\n",
        "\n",
        "        d_loss = loss_D(non_makeup, makeup, z_transfer.detach(), z_removal.detach())\n",
        "        d_loss = d_loss / accumulation_steps\n",
        "        d_loss.backward()\n",
        "\n",
        "        loss_D.requires_grad_(False)\n",
        "        g_loss, loss_distr, _, _, _, _, _, _, _, _ =\\\n",
        "            loss_G(non_makeup, makeup, transfer_g, removal_g, non_makeup_parse, makeup_parse, g_output, weighted=True)\n",
        "        g_loss = g_loss / accumulation_steps\n",
        "        g_loss.backward()\n",
        "        loss_D.requires_grad_(True)\n",
        "\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            optimizer_G.step()\n",
        "            optimizer_D.step()\n",
        "            optimizer_G.zero_grad()\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "        loss_stat.d_loss_mean += d_loss.item() * accumulation_steps / len(data_loader)\n",
        "        loss_stat.g_loss_mean += g_loss.item() * accumulation_steps / len(data_loader)\n",
        "        loss_stat.loss_G_GAN_mean += loss_distr[0] * g_loss.item() / len(data_loader)\n",
        "        loss_stat.loss_G_rec_mean += loss_distr[1] * g_loss.item() / len(data_loader)\n",
        "        loss_stat.loss_G_cycle_mean += loss_distr[2] * g_loss.item() / len(data_loader)\n",
        "        loss_stat.loss_G_semantic_mean += loss_distr[3] * g_loss.item() / len(data_loader)\n",
        "        loss_stat.loss_G_SPL_mean += loss_distr[4] * g_loss.item() / len(data_loader)\n",
        "\n",
        "    if epoch % opts.print_iter == 0:\n",
        "        print(\"epoch     :\\t\", epoch)\n",
        "        loss_stat.print_diff(loss_stat_prev)\n",
        "        print(\"\\n\")\n",
        "    if epoch % opts.save_checkpoint_epochs == 0:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_G_state_dict': G.state_dict(),\n",
        "            'model_D_non_makeup_state_dict': D_non_makeup.state_dict(),\n",
        "            'model_D_makeup_state_dict': D_makeup.state_dict(),\n",
        "            'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
        "            'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
        "            'g_loss': loss_stat.g_loss_mean,\n",
        "            'd_loss': loss_stat.d_loss_mean,\n",
        "            }, opts.outputs_dir + opts.name + str(epoch) + '.tar')\n",
        "    data_loader.dataset.move_warp_to_storage()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MireIDVW-Utg"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8xka3nfvri8",
        "outputId": "f4988bcc-d0aa-4d39-bafe-5a3582f8e403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/train\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/train\n",
        "!tar -c -f new_warp30.tar warp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYok5-vF4UIj"
      },
      "outputs": [],
      "source": [
        "%cp -r /content/drive/MyDrive/train/warp /content/BMT/datasets/train/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrxnuC1akV0b",
        "outputId": "a57f4b00-679c-40a5-f245-057320a8aead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 2/2 [00:06<00:00,  3.15s/it]\n",
            "100% 24/24 [00:02<00:00,  8.28it/s]\n"
          ]
        }
      ],
      "source": [
        "# Run for dataset generation without training\n",
        "!python3 /content/BMT/run_generator.py --warp-path '/content/BMT/datasets/test/images/warp_tmp' \\\n",
        "--warp-alt-path '/content/BMT/datasets/test/images/warp' \\\n",
        "--warp-storage '/content/drive/MyDrive/test/warp' \\\n",
        "--storage-every 300 \\\n",
        "--non-makeup-dir '/content/BMT/datasets/test/images/non-makeup' \\\n",
        "--non-makeup-mask-dir '/content/BMT/datasets/test/seg1/non-makeup' \\\n",
        "--non-makeup-lms-dir '/content/BMT/datasets/test/lms/non-makeup' \\\n",
        "--makeup-dir '/content/BMT/datasets/test/images/makeup' \\\n",
        "--makeup-mask-dir '/content/BMT/datasets/test/seg1/makeup' \\\n",
        "--makeup-lms-dir '/content/BMT/datasets/test/lms/makeup' \\\n",
        "--skip-to-index 36300 \\\n",
        "--metadata-only\n",
        "#--skip-metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leysafOMZA54",
        "outputId": "958731ab-e989-4ce8-f24a-68f0adb92aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123M\t/content/drive/MyDrive/train/warp\n"
          ]
        }
      ],
      "source": [
        "!du -sh /content/drive/MyDrive/train/warp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMir9Ss9OWQO",
        "outputId": "bff6ab25-3808-4541-c44a-1a40ab0744f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124M\t/content/BMT/datasets/train/images/warp\n"
          ]
        }
      ],
      "source": [
        "!du -sh /content/BMT/datasets/train/images/warp"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UCdeXzBQOo9W"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}