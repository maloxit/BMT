{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4xnkGyiZzm9",
        "outputId": "f5b43a16-aa61-494a-88db-b9a940b5c173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kaC8pFTs999Q"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = '/content/drive/MyDrive/train/outputs/BMT_NND_WM110.tar'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCdeXzBQOo9W"
      },
      "source": [
        "# Инициализация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GeV-eQ7VgZR",
        "outputId": "56e0868f-a792-4adf-df3d-a258e55bd8f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore) (1.22.4)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (2.2.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore) (0.8.10)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath>=0.1.7->fvcore) (4.5.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=054bade40f7740c813fd8834d5edacc3b7369fd6d18ea14f5979261ebdd44666\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=ee694e5cb3664839601d256155c9dc0152a3e16618ab5df3fb6c37974fa0c353\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, jsonpickle, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 jsonpickle-3.0.1 portalocker-2.7.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install fvcore jsonpickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIWbU1MGRsNn",
        "outputId": "7bc00874-05cf-4aac-d906-deee442a25cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'BMT'...\n",
            "remote: Enumerating objects: 2180, done.\u001b[K\n",
            "remote: Counting objects: 100% (2180/2180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2164/2164), done.\u001b[K\n",
            "remote: Total 2180 (delta 14), reused 2149 (delta 12), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2180/2180), 285.53 MiB | 34.12 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n",
            "Updating files: 100% (2147/2147), done.\n",
            "/content/BMT\n",
            "Already on 'develop'\n",
            "Your branch is up to date with 'origin/develop'.\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b develop --single-branch --depth 1 'https://github.com/maloxit/BMT.git'\n",
        "%cd /content/BMT\n",
        "!git checkout develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkedGrutqd8W",
        "outputId": "e7635477-84b2-4045-efc3-9a1b275c3837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BMT\n"
          ]
        }
      ],
      "source": [
        "%cd /content/BMT\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.utils.data as torchdt\n",
        "from itertools import chain\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from model.option import get_opts\n",
        "from model.dataset import MakeupDataset\n",
        "from model.loss import SAATDLoss, SAATGLoss\n",
        "from model.model import get_generator, get_dis_non_makeup, get_dis_makeup\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ABP8cRq7qjIb"
      },
      "outputs": [],
      "source": [
        "def get_torch_device(opts):\n",
        "    if opts.platform == 'GPU' and torch.cuda.is_available():\n",
        "        return torch.device('cuda:{}'.format(opts.device_id))\n",
        "    else:\n",
        "        return torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sEWIYIiMq2QL"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "opts = argparse.Namespace(**{\n",
        "    'warp_dir': '/content/BMT/datasets/train/images/warp_tmp',\n",
        "    'warp_alt_dir': '/content/BMT/datasets/train/images/warp',\n",
        "    'warp_storage_dir': '/content/drive/MyDrive/train/warp',\n",
        "    'subset_config_files': \n",
        "    [\n",
        "        'datasets/train_makeup_blue_shades.json',\n",
        "        'datasets/train_makeup_dark_shades.json',\n",
        "        'datasets/train_makeup_new_makeup.json',\n",
        "        'datasets/train_makeup_other.json',\n",
        "        'datasets/train_makeup_purpule_shades.json',\n",
        "        'datasets/train_makeup_red_eyes.json',\n",
        "        'datasets/train_non_makeup.json'\n",
        "    ],\n",
        "    'input_dim': 3,\n",
        "    'output_dim': 3,\n",
        "    'semantic_dim': 18,\n",
        "    'batch_size': 1,\n",
        "    'resize_size': 286,\n",
        "    'crop_size': 256,\n",
        "    'flip': True,\n",
        "    'nThreads': 0,\n",
        "\n",
        "    # platform related\n",
        "    'platform': 'GPU',\n",
        "    'device_id': 0,\n",
        "    'device_num': 1,\n",
        "\n",
        "    # ouptput related\n",
        "    'name': 'BMT_NND_WM_DHP',\n",
        "    'outputs_dir': '/content/drive/MyDrive/train/outputs/',\n",
        "    'print_iter': 1,\n",
        "    'save_imgs': True,\n",
        "    'save_checkpoint_epochs': 5,\n",
        "\n",
        "    # weight\n",
        "    'gan_mode': 'lsgan',\n",
        "    'rec_weight': 1,\n",
        "    'CP_weight': 0.05,\n",
        "    'GP_weight': 0.025,\n",
        "    'cycle_weight': 1,\n",
        "    'adv_weight': 1,\n",
        "    'semantic_weight': 1,\n",
        "\n",
        "    # training related\n",
        "    'init_type': 'normal',\n",
        "    'init_gain': 0.02,\n",
        "    'beta1': 0.5,\n",
        "    'beta2': 0.999,\n",
        "\n",
        "    'dis_scale': 3,\n",
        "    'dis_norm': 'None',\n",
        "    'dis_spectral_norm': True,\n",
        "    'lr_policy': 'lambda',\n",
        "    'max_epoch': 1000,\n",
        "    'n_epochs': 1000,\n",
        "    'n_epochs_decay': 500,\n",
        "\n",
        "    'resume': None,\n",
        "    'num_residule_block': 4,\n",
        "    'lr': 0.0002\n",
        "})\n",
        "test_opts = argparse.Namespace(**{\n",
        "    'warp_dir': '/content/BMT/datasets/test/images/warp_tmp',\n",
        "    'warp_alt_dir': '/content/BMT/datasets/test/images/warp',\n",
        "    'warp_storage_dir': '/content/drive/MyDrive/test/warp',\n",
        "    'subset_config_files': \n",
        "    [\n",
        "        'datasets/test_makeup.json',\n",
        "        'datasets/test_non_makeup.json'\n",
        "    ],\n",
        "    'input_dim': 3,\n",
        "    'output_dim': 3,\n",
        "    'semantic_dim': 18,\n",
        "    'batch_size': 1,\n",
        "    'resize_size': 286,\n",
        "    'crop_size': 256,\n",
        "    'flip': True,\n",
        "    'nThreads': 0,\n",
        "\n",
        "    # platform related\n",
        "    'platform': 'GPU',\n",
        "    'device_id': 0,\n",
        "    'device_num': 1,\n",
        "\n",
        "    # ouptput related\n",
        "    'name': 'BMT_ND_WM',\n",
        "    'outputs_dir': '/content/drive/MyDrive/test/outputs/',\n",
        "    'print_iter': 1,\n",
        "    'save_imgs': True,\n",
        "    'save_checkpoint_epochs': 5,\n",
        "\n",
        "    # weight\n",
        "    'gan_mode': 'lsgan',\n",
        "    'rec_weight': 1,\n",
        "    'CP_weight': 0.05,\n",
        "    'GP_weight': 0.025,\n",
        "    'cycle_weight': 1,\n",
        "    'adv_weight': 1,\n",
        "    'semantic_weight': 1,\n",
        "\n",
        "    # training related\n",
        "    'init_type': 'normal',\n",
        "    'init_gain': 0.02,\n",
        "    'beta1': 0.5,\n",
        "    'beta2': 0.999,\n",
        "\n",
        "    'dis_scale': 3,\n",
        "    'dis_norm': 'None',\n",
        "    'dis_spectral_norm': True,\n",
        "    'lr_policy': 'lambda',\n",
        "    'max_epoch': 1000,\n",
        "    'n_epochs': 1000,\n",
        "    'n_epochs_decay': 500,\n",
        "\n",
        "    'resume': None,\n",
        "    'num_residule_block': 4,\n",
        "    'lr': 0.0002\n",
        "})\n",
        "\n",
        "device = get_torch_device(opts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxcKJ4ISq8Nh",
        "outputId": "3f877222-653e-4e60-f3ed-726ec7351d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n"
          ]
        }
      ],
      "source": [
        "# model G and D\n",
        "G = get_generator(opts, device)\n",
        "D_non_makeup = get_dis_non_makeup(opts, device)\n",
        "D_makeup = get_dis_makeup(opts, device)\n",
        "\n",
        "# loss G and D\n",
        "loss_G = SAATGLoss(opts, G, D_non_makeup, D_makeup)\n",
        "loss_D = SAATDLoss(opts, D_non_makeup, D_makeup)\n",
        "\n",
        "# optimizer G and D\n",
        "optimizer_G = torch.optim.Adam(G.parameters(), opts.lr, betas=(opts.beta1, opts.beta2), weight_decay=0.0001)\n",
        "optimizer_D = torch.optim.Adam(chain(D_non_makeup.parameters(), D_makeup.parameters()), opts.lr,\n",
        "                                betas=(opts.beta1, opts.beta2), weight_decay=0.0001)\n",
        "\n",
        "last_epoch = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EkUUYprKaZeZ"
      },
      "outputs": [],
      "source": [
        "# Load checkpoint\n",
        "\n",
        "def load_checkpoint(checkpoint_path, G=None, D_non_makeup=None, D_makeup=None, optimizer_G=None, optimizer_D=None):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    if G is not None:\n",
        "        G.load_state_dict(checkpoint['model_G_state_dict'])\n",
        "    if D_non_makeup is not None:\n",
        "        D_non_makeup.load_state_dict(checkpoint['model_D_non_makeup_state_dict'])\n",
        "    if D_makeup is not None:\n",
        "        D_makeup.load_state_dict(checkpoint['model_D_makeup_state_dict'])\n",
        "    if optimizer_G is not None:\n",
        "        optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
        "    if optimizer_D is not None:\n",
        "        optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])\n",
        "    last_epoch = checkpoint['epoch']\n",
        "    last_g_loss = checkpoint['g_loss']\n",
        "    last_d_loss = checkpoint['d_loss']\n",
        "\n",
        "    print(\"Loading checkpoint\")\n",
        "    print(\"epoch:\\t\", last_epoch)\n",
        "    print(\"g_loss\\t\", last_g_loss)\n",
        "    print(\"d_loss\\t\", last_d_loss)\n",
        "    print(\"\\n\")\n",
        "    return last_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5uEP4BdQWsY"
      },
      "source": [
        "# Загрузка сгенерированной части датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvvDrAVYceIo",
        "outputId": "2c037c48-9749-4228-ee23-6fc64c0db48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1XlPg2kbqErZxkHHF0ISCVJ5Nw6vXsMm2/train\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/train\n",
        "!tar -xPf new_warp1.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp2.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp3.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp4.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp5.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp6.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp7.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp8.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp9.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp10.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp11.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp12.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp13.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp14.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp15.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp16.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp17.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp18.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp19.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp20.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp21.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp22.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp23.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp24.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp25.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp26.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp27.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp28.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp29.tar -C /content/BMT/datasets/train/images\n",
        "!tar -xPf new_warp30.tar -C /content/BMT/datasets/train/images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biDEiXuLPSZ5"
      },
      "source": [
        "# Тест"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDkpxD4-f_gv",
        "outputId": "4a063e81-e011-49ac-a73d-26e80798117a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BMT\n",
            "non_makeup size: 6 makeup size: 34\n",
            "Loading checkpoint\n",
            "epoch:\t 110\n",
            "g_loss\t -2.249089557329813\n",
            "d_loss\t 0.4295520579814914\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 204/204 [03:13<00:00,  1.05it/s]\n"
          ]
        }
      ],
      "source": [
        "def write_test_pair_img(result_dir, test_pair_img, iter):\n",
        "    if not os.path.exists(result_dir):\n",
        "        os.makedirs(result_dir)\n",
        "    img_filename = '%s/gen_%05d.png' % (result_dir, iter)\n",
        "    torchvision.utils.save_image(test_pair_img / 2 + 0.5, img_filename, nrow=1)\n",
        "\n",
        "\n",
        "def normalize_image(x):\n",
        "    return x[:, 0:3, :, :]\n",
        "\n",
        "\n",
        "def get_img(non_makeup, makeup, z_transfer, z_removal, transfer_g, removal_g, z_rec_non_makeup, z_rec_makeup, z_cycle_non_makeup, z_cycle_makeup):\n",
        "    #non_makeup_down = normalize_image(F.interpolate(non_makeup, scale_factor=0.25, mode='nearest'))\n",
        "    #n, c, h, w = non_makeup_down.shape\n",
        "    #non_makeup_down_warp = torch.bmm(non_makeup_down.view(n, c, h * w), mapY)  # n*HW*1\n",
        "    #non_makeup_down_warp = non_makeup_down_warp.view(n, c, h, w)\n",
        "    #non_makeup_warp = F.interpolate(non_makeup_down_warp, scale_factor=4)\n",
        "\n",
        "    #makeup_down = normalize_image(F.interpolate(makeup, scale_factor=0.25, mode='nearest'))\n",
        "    #n, c, h, w = makeup_down.shape\n",
        "    #makeup_down_warp = torch.bmm(makeup_down.view(n, c, h * w), mapX)  # n*HW*1\n",
        "    #makeup_down_warp = makeup_down_warp.view(n, c, h, w)\n",
        "    #makeup_warp = F.interpolate(makeup_down_warp, scale_factor=4)\n",
        "\n",
        "    n, c, h, w = non_makeup.shape\n",
        "\n",
        "    canvas = torch.ones([1, c, int(h * 4.5), int(w * 4)])\n",
        "\n",
        "\n",
        "    images_non_makeup = normalize_image(non_makeup).detach()\n",
        "    images_makeup = normalize_image(makeup).detach()\n",
        "    images_z_transfer = normalize_image(z_transfer).detach()\n",
        "    images_z_removal = normalize_image(z_removal).detach()\n",
        "    images_g_transfer = normalize_image(transfer_g).detach()\n",
        "    images_g_removal = normalize_image(removal_g).detach()\n",
        "    images_z_rec_non_makeup = normalize_image(z_rec_non_makeup).detach()\n",
        "    images_z_rec_makeup = normalize_image(z_rec_makeup).detach()\n",
        "    images_z_cycle_non_makeup = normalize_image(z_cycle_non_makeup).detach()\n",
        "    images_z_cycle_makeup = normalize_image(z_cycle_makeup).detach()\n",
        "\n",
        "    canvas[0:1, :, int(h * 1): int(h * 1) + h, int(w * 0):int(w * 0)+w] = images_non_makeup[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 2.5): int(h * 2.5) + h, int(w * 0):int(w * 0)+w] = images_makeup[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 1): int(h * 1) + h, int(w * 1):int(w * 1)+w] = images_z_transfer[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 2.5): int(h * 2.5) + h, int(w * 1):int(w * 1)+w] = images_z_removal[0:1, ::]\n",
        "\n",
        "    canvas[0:1, :, int(h * 1): int(h * 1) + h, int(w * 2):int(w * 2)+w] = images_z_cycle_non_makeup[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 2.5): int(h * 2.5) + h, int(w * 2):int(w * 2)+w] = images_z_cycle_makeup[0:1, ::]\n",
        "\n",
        "    canvas[0:1, :, int(h * 1): int(h * 1) + h, int(w * 3):int(w * 3)+w] = images_z_rec_non_makeup[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 2.5): int(h * 2.5) + h, int(w * 3):int(w * 3)+w] = images_z_rec_makeup[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 0): int(h * 0) + h, int(w * 1):int(w * 1)+w] = images_g_transfer[0:1, ::]\n",
        "    \n",
        "    canvas[0:1, :, int(h * 3.5): int(h * 3.5) + h, int(w * 1):int(w * 1)+w] = images_g_removal[0:1, ::]\n",
        "\n",
        "\n",
        "\n",
        "    #row1 = torch.cat((images_non_makeup[0:1, ::],images_makeup[0:1, ::], makeup_warp[0:1, ::], images_z_transfer[0:1, ::], images_z_removal[0:1, ::], images_g_transfer[0:1, ::], images_g_removal[0:1, ::]), 3)\n",
        "    return canvas\n",
        "\n",
        "\n",
        "%cd /content/BMT\n",
        "checkpoint_path2 = '/content/drive/MyDrive/train/outputs/BMT_NND_WM110.tar'\n",
        "\n",
        "#dataset = MakeupDataset(opts, device, ['datasets/train_non_makeup.json', 'datasets/train_makeup_new_makeup.json'], transform=False, need_pgt=True, all_comb=False)\n",
        "dataset = MakeupDataset(test_opts, device, ['datasets/test_non_makeup.json', 'datasets/test_makeup.json'], transform=False, need_pgt=True, all_comb=True, add_original_parsing=True)\n",
        "data_loader = torchdt.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=opts.nThreads)\n",
        "\n",
        "last_epoch = load_checkpoint(checkpoint_path2, G)\n",
        "#last_epoch = 1000\n",
        "G.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(tqdm(data_loader)):\n",
        "        non_makeup = data['non_makeup'].to(device)\n",
        "        makeup = data['makeup'].to(device)\n",
        "        transfer_g = data['transfer'].to(device)\n",
        "        removal_g = data['removal'].to(device)\n",
        "        non_makeup_parse = data['non_makeup_parse'].to(device)\n",
        "        makeup_parse = data['makeup_parse'].to(device)\n",
        "\n",
        "\n",
        "        non_makeup_parse_original = data['non_makeup_parse_original'].to(device)\n",
        "        makeup_parse_original = data['makeup_parse_original'].to(device)\n",
        "\n",
        "        z_transfer, z_removal, z_rec_non_makeup, z_rec_makeup, z_cycle_non_makeup, z_cycle_makeup, _, _ =\\\n",
        "            G(non_makeup, makeup, non_makeup_parse, makeup_parse)\n",
        "        #z_transfer, z_removal, z_rec_non_makeup, z_rec_makeup, z_cycle_non_makeup, z_cycle_makeup, _, _ =\\\n",
        "            #G_old(non_makeup, makeup, non_makeup_parse_original, makeup_parse_original)\n",
        "        #img = get_img(non_makeup, makeup, mapX, mapY, z_transfer, z_removal, transfer_g, removal_g)\n",
        "        img = get_img(non_makeup, makeup, z_transfer, z_removal, transfer_g, removal_g, z_rec_non_makeup, z_rec_makeup, z_cycle_non_makeup, z_cycle_makeup)\n",
        "        write_test_pair_img(test_opts.outputs_dir + 'res{}'.format(last_epoch), img, i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from original_SSAT_model.model import MakeupGAN as SSAT_GAN\n",
        "\n",
        "G_old = SSAT_GAN(test_opts, device)\n",
        "G_old.resume('/content/BMT/original_SSAT_model/weights/SSAT.pth')\n",
        "\n",
        "last_epoch2 = 1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8WoczyDzEzZ",
        "outputId": "d485415e-fa85-4de6-dc51-da6c0a5b8031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmo8nbR1tFGn",
        "outputId": "f395ef52-b173-4fe9-9da1-f2b2c34e8149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BMT\n",
            "non_makeup size: 6 makeup size: 34\n",
            "Loading checkpoint\n",
            "epoch:\t 110\n",
            "g_loss\t -2.249089557329813\n",
            "d_loss\t 0.4295520579814914\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 204/204 [06:09<00:00,  1.81s/it]\n"
          ]
        }
      ],
      "source": [
        "%cd /content/BMT\n",
        "\n",
        "checkpoint_path1 = '/content/drive/MyDrive/train/outputs/BMT_NND_WM110.tar'\n",
        "#checkpoint_path2 = '/content/drive/MyDrive/train/outputs/BMT_ND_WM240.tar'\n",
        "#checkpoint_path2 = '/content/drive/MyDrive/train/outputs/BMT_NND_WM85.tar'\n",
        "\n",
        "\n",
        "dataset = MakeupDataset(test_opts, device, test_opts.subset_config_files, transform=False, need_pgt=True, all_comb=True, add_original_parsing=True)\n",
        "data_loader = torchdt.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=opts.nThreads)\n",
        "\n",
        "\n",
        "last_epoch1 = load_checkpoint(checkpoint_path1, G)\n",
        "#last_epoch2 = load_checkpoint(checkpoint_path2, G_old)\n",
        "G.eval()\n",
        "G_old.eval()\n",
        "refs = []\n",
        "trans1 = []\n",
        "trans2 = []\n",
        "pgts = []\n",
        "bases = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(tqdm(data_loader)):\n",
        "        non_makeup = data['non_makeup'].to(device)\n",
        "        makeup = data['makeup'].to(device)\n",
        "        transfer_g = data['transfer'].to(device)\n",
        "        removal_g = data['removal'].to(device)\n",
        "        non_makeup_parse = data['non_makeup_parse'].to(device)\n",
        "        makeup_parse = data['makeup_parse'].to(device)\n",
        "\n",
        "\n",
        "        non_makeup_parse_original = data['non_makeup_parse_original'].to(device)\n",
        "        makeup_parse_original = data['makeup_parse_original'].to(device)\n",
        "\n",
        "        base_index = i // dataset.makeup_size\n",
        "        ref_index = i % dataset.makeup_size\n",
        "        if ref_index == 0:\n",
        "            bases.append(non_makeup[0].detach().cpu() / 2 + 0.5)\n",
        "            refs.append([])\n",
        "            trans1.append([])\n",
        "            trans2.append([])\n",
        "            pgts.append([])\n",
        "        refs[base_index].append(makeup[0].detach().cpu() / 2 + 0.5)\n",
        "        pgts[base_index].append(transfer_g[0].detach().cpu() / 2 + 0.5)\n",
        "        z_transfer1, z_removal1 =\\\n",
        "            G.get_transfers(non_makeup, makeup, non_makeup_parse, makeup_parse)\n",
        "        z_transfer2, z_removal2 =\\\n",
        "            G_old.get_transfers(non_makeup, makeup, non_makeup_parse_original, makeup_parse_original)\n",
        "        trans1[base_index].append(z_transfer1[0].detach().cpu() / 2 + 0.5)\n",
        "        trans2[base_index].append(z_transfer2[0].detach().cpu() / 2 + 0.5)\n",
        "    nrow = 6\n",
        "    plain = torch.ones_like(bases[0])\n",
        "    for i in range(dataset.non_makeup_size):\n",
        "        for j in range((dataset.makeup_size + nrow - 1) // nrow):\n",
        "            imgs = []\n",
        "            imgs.append(bases[i])\n",
        "            imgs += refs[i][j*nrow:min((j+1)*nrow, dataset.makeup_size)]\n",
        "            imgs.append(plain)\n",
        "            imgs += trans2[i][j*nrow:min((j+1)*nrow, dataset.makeup_size)]\n",
        "            imgs.append(plain)\n",
        "            imgs += trans1[i][j*nrow:min((j+1)*nrow, dataset.makeup_size)]\n",
        "            imgs.append(plain)\n",
        "            imgs += pgts[i][j*nrow:min((j+1)*nrow, dataset.makeup_size)]\n",
        "            result_dir = test_opts.outputs_dir + 'res{}_{}'.format(last_epoch1, last_epoch2)\n",
        "            if not os.path.exists(result_dir):\n",
        "                os.makedirs(result_dir)\n",
        "            img_filename = '%s/table_%05d.png' % (result_dir, i * 10 + j)\n",
        "            torchvision.utils.save_image(imgs, img_filename, nrow=1 + min(nrow, dataset.makeup_size - j*nrow))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkuxG4c1PYgD"
      },
      "source": [
        "# Обучение"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rize_func(x, k):\n",
        "    return 1 - (np.cos(np.pi * x / 2)) ** k\n",
        "\n",
        "def interp(x, a, b, l, k):\n",
        "    if x > l:\n",
        "        return b\n",
        "    else:\n",
        "        return (b-a) * rize_func(x/l, k) + a\n",
        "\n",
        "def GetDinamicHyperparams(epoch):\n",
        "    hyperparams = {\n",
        "        'rec_weight': interp(epoch, 0.1, 0.5, 100, 2),\n",
        "        'CP_weight': 0.05,\n",
        "        'GP_weight': 0.025,\n",
        "        'cycle_weight': interp(epoch, 0.1, 0.5, 100, 2),\n",
        "        'adv_weight': 1,\n",
        "        'semantic_weight': 1,\n",
        "        'area_weights': [0.05, 0.75, 1., 1., 1., 1., 1., 2., 1, 2., 0.2, 1., 1., 0.5],\n",
        "        'eye_shadows_weight': interp(epoch, 2., 1.5, 100, 2),\n",
        "    }\n",
        "    return hyperparams\n"
      ],
      "metadata": {
        "id": "dz2SvxBaISzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JASQP1MjqYbH"
      },
      "outputs": [],
      "source": [
        "%cd /content/BMT\n",
        "\n",
        "dataset = MakeupDataset(opts, device, opts.subset_config_files, transform=True, need_pgt=True, all_comb=False)\n",
        "data_loader = torchdt.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=opts.nThreads)\n",
        "\n",
        "accumulation_steps = 1\n",
        "\n",
        "#last_epoch = load_checkpoint(checkpoint_path, G, D_non_makeup, D_makeup, optimizer_G, optimizer_D)\n",
        "#last_epoch = load_checkpoint(checkpoint_path, G, D_non_makeup, D_makeup)\n",
        "G.train()\n",
        "D_non_makeup.train()\n",
        "D_makeup.train()\n",
        "optimizer_G.zero_grad()\n",
        "optimizer_D.zero_grad()\n",
        "\n",
        "\n",
        "class LossStatState:\n",
        "    def __init__(self):\n",
        "        self.d_loss_mean = 0.0\n",
        "        self.g_loss_mean = 0.0\n",
        "        self.loss_G_GAN_mean = 0.0\n",
        "        self.loss_G_rec_mean = 0.0\n",
        "        self.loss_G_cycle_mean = 0.0\n",
        "        self.loss_G_semantic_mean = 0.0\n",
        "        self.loss_G_SPL_mean = 0.0\n",
        "\n",
        "    def print_diff(self, prev_state):\n",
        "        print(\"g_loss    :\\t\", self.g_loss_mean, \"\\tdiff:\\t\", self.g_loss_mean - prev_state.g_loss_mean)\n",
        "        print(\"d_loss    :\\t\", self.d_loss_mean, \"\\tdiff:\\t\", self.d_loss_mean - prev_state.d_loss_mean)\n",
        "        print(\"G_GAN     :\\t\", self.loss_G_GAN_mean, \"\\tdiff:\\t\", self.loss_G_GAN_mean - prev_state.loss_G_GAN_mean)\n",
        "        print(\"G_rec     :\\t\", self.loss_G_rec_mean, \"\\tdiff:\\t\", self.loss_G_rec_mean - prev_state.loss_G_rec_mean)\n",
        "        print(\"G_cycle   :\\t\", self.loss_G_cycle_mean, \"\\tdiff:\\t\", self.loss_G_cycle_mean - prev_state.loss_G_cycle_mean)\n",
        "        print(\"G_semantic:\\t\", self.loss_G_semantic_mean, \"\\tdiff:\\t\", self.loss_G_semantic_mean - prev_state.loss_G_semantic_mean)\n",
        "        print(\"G_SPL     :\\t\", self.loss_G_SPL_mean, \"\\tdiff:\\t\", self.loss_G_SPL_mean - prev_state.loss_G_SPL_mean)\n",
        "\n",
        "\n",
        "loss_stat = LossStatState()\n",
        "for epoch in range(last_epoch + 1, opts.max_epoch):\n",
        "    loss_stat_prev = loss_stat\n",
        "    loss_stat = LossStatState()\n",
        "\n",
        "    hyperparams = GetDinamicHyperparams(epoch)\n",
        "    print('hyperparams:')\n",
        "    print('rec_weight    :\\t', hyperparams['rec_weight'])\n",
        "    print('cycle_weight    :\\t', hyperparams['cycle_weight'])\n",
        "    print('eye_shadows_weight    :\\t', hyperparams['eye_shadows_weight'])\n",
        "    \n",
        "    for i, data in enumerate(tqdm(data_loader)):\n",
        "\n",
        "        non_makeup = data['non_makeup'].to(device)\n",
        "        makeup = data['makeup'].to(device)\n",
        "        transfer_g = data['transfer'].to(device)\n",
        "        removal_g = data['removal'].to(device)\n",
        "        non_makeup_parse = data['non_makeup_parse'].to(device)\n",
        "        makeup_parse = data['makeup_parse'].to(device)\n",
        "\n",
        "        g_output = G(non_makeup, makeup, non_makeup_parse, makeup_parse)\n",
        "\n",
        "        z_transfer = g_output[0]\n",
        "        z_removal = g_output[1]\n",
        "\n",
        "        d_loss = loss_D(non_makeup, makeup, z_transfer.detach(), z_removal.detach())\n",
        "        d_loss = d_loss / accumulation_steps\n",
        "        d_loss.backward()\n",
        "\n",
        "        loss_D.requires_grad_(False)\n",
        "        g_loss, loss_distr, _, _, _, _, _, _, _, _ =\\\n",
        "            loss_G(non_makeup, makeup, transfer_g, removal_g, non_makeup_parse, makeup_parse, hyperparams, g_output)\n",
        "        g_loss = g_loss / accumulation_steps\n",
        "        g_loss.backward()\n",
        "        loss_D.requires_grad_(True)\n",
        "\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            optimizer_G.step()\n",
        "            optimizer_D.step()\n",
        "            optimizer_G.zero_grad()\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "        loss_stat.d_loss_mean += d_loss.item() * accumulation_steps / len(data_loader)\n",
        "        loss_stat.g_loss_mean += g_loss.item() * accumulation_steps / len(data_loader)\n",
        "        loss_stat.loss_G_GAN_mean += loss_distr[0] * g_loss.item() / len(data_loader)\n",
        "        loss_stat.loss_G_rec_mean += loss_distr[1] * g_loss.item() / len(data_loader)\n",
        "        loss_stat.loss_G_cycle_mean += loss_distr[2] * g_loss.item() / len(data_loader)\n",
        "        loss_stat.loss_G_semantic_mean += loss_distr[3] * g_loss.item() / len(data_loader)\n",
        "        loss_stat.loss_G_SPL_mean += loss_distr[4] * g_loss.item() / len(data_loader)\n",
        "\n",
        "    if epoch % opts.print_iter == 0:\n",
        "        print(\"epoch     :\\t\", epoch)\n",
        "        loss_stat.print_diff(loss_stat_prev)\n",
        "        print(\"\\n\")\n",
        "    if epoch % opts.save_checkpoint_epochs == 0:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_G_state_dict': G.state_dict(),\n",
        "            'model_D_non_makeup_state_dict': D_non_makeup.state_dict(),\n",
        "            'model_D_makeup_state_dict': D_makeup.state_dict(),\n",
        "            'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
        "            'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
        "            'g_loss': loss_stat.g_loss_mean,\n",
        "            'd_loss': loss_stat.d_loss_mean,\n",
        "            }, opts.outputs_dir + opts.name + str(epoch) + '.tar')\n",
        "    data_loader.dataset.move_warp_to_storage()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MireIDVW-Utg"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8xka3nfvri8",
        "outputId": "f4988bcc-d0aa-4d39-bafe-5a3582f8e403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/train\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/train\n",
        "!tar -c -f new_warp30.tar warp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYok5-vF4UIj"
      },
      "outputs": [],
      "source": [
        "%cp -r /content/drive/MyDrive/train/warp /content/BMT/datasets/train/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrxnuC1akV0b",
        "outputId": "a57f4b00-679c-40a5-f245-057320a8aead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 2/2 [00:06<00:00,  3.15s/it]\n",
            "100% 24/24 [00:02<00:00,  8.28it/s]\n"
          ]
        }
      ],
      "source": [
        "# Run for dataset generation without training\n",
        "!python3 /content/BMT/run_generator.py --warp-path '/content/BMT/datasets/test/images/warp_tmp' \\\n",
        "--warp-alt-path '/content/BMT/datasets/test/images/warp' \\\n",
        "--warp-storage '/content/drive/MyDrive/test/warp' \\\n",
        "--storage-every 300 \\\n",
        "--non-makeup-dir '/content/BMT/datasets/test/images/non-makeup' \\\n",
        "--non-makeup-mask-dir '/content/BMT/datasets/test/seg1/non-makeup' \\\n",
        "--non-makeup-lms-dir '/content/BMT/datasets/test/lms/non-makeup' \\\n",
        "--makeup-dir '/content/BMT/datasets/test/images/makeup' \\\n",
        "--makeup-mask-dir '/content/BMT/datasets/test/seg1/makeup' \\\n",
        "--makeup-lms-dir '/content/BMT/datasets/test/lms/makeup' \\\n",
        "--skip-to-index 36300 \\\n",
        "--metadata-only\n",
        "#--skip-metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leysafOMZA54",
        "outputId": "958731ab-e989-4ce8-f24a-68f0adb92aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123M\t/content/drive/MyDrive/train/warp\n"
          ]
        }
      ],
      "source": [
        "!du -sh /content/drive/MyDrive/train/warp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMir9Ss9OWQO",
        "outputId": "bff6ab25-3808-4541-c44a-1a40ab0744f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124M\t/content/BMT/datasets/train/images/warp\n"
          ]
        }
      ],
      "source": [
        "!du -sh /content/BMT/datasets/train/images/warp"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UCdeXzBQOo9W",
        "biDEiXuLPSZ5"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}